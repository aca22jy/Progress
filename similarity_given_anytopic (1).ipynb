{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "similarity_given_anytopic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kExqarv-DAhg"
      },
      "source": [
        "This notebook is for: given an arbitrary topic/term, return related topics. Here we shows the top 20. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYzu4quURS7z",
        "outputId": "0c920b2a-8087-402e-ee1a-62af038be7fc"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 36.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL9DbGpLRMGy"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances, linear_kernel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import torch\n",
        "import math\n",
        "import pickle"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYy2YJSgsYlc"
      },
      "source": [
        "## Define model and load saved embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AewJc_USD0Eu"
      },
      "source": [
        "Define which model we want to use: BERT or ClinicalBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNArBO4YF226"
      },
      "source": [
        "model = 'ClinicalBERT' # if want to use BERT, change 'ClinicalBERT' to 'BERT'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-S7JasxRUPk",
        "outputId": "fbc964b7-d2cc-43a9-e6fb-de760a9cf46a"
      },
      "source": [
        "if model == 'ClinicalBERT': \n",
        "  model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
        "  !wget https://github.com/casszhao/FAIR/raw/main/sources/ClinicalBERT_embeddings.pkl\n",
        "  embeddings_file_name = 'ClinicalBERT_embeddings.pkl'\n",
        "elif model_name == 'sentence-transformers/bert-base-nli-mean-tokens':\n",
        "  !wget https://github.com/casszhao/FAIR/raw/main/sources/BERT_embeddings.pkl\n",
        "  embeddings_file_name = 'BERT_embeddings.pkl'\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "with open(embeddings_file_name,'rb') as f:\n",
        "  Embeddings = pickle.load(f)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jmqZImRsOC-"
      },
      "source": [
        "## Load candidate categories list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSkdaaUsEdbL"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/casszhao/FAIR/main/sources/0901_full_list.csv'\n",
        "sorted_cat = pd.read_csv(url, header=None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8go-yG1v6e6n"
      },
      "source": [
        "get a dictionary for embedding looking up later, the key is the numerical index as the embeddings list share the same order of the candidate list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBpvpU04cp89"
      },
      "source": [
        "sorted_cat = sorted_cat[0].to_list()\n",
        "sorted_cat = list(dict.fromkeys(sorted_cat))\n",
        "\n",
        "a = (map(lambda x: x.lower(), sorted_cat))\n",
        "lower_cat = list(a)\n",
        "dic = {v: k for v, k in enumerate(lower_cat)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNWTwy2d7Cs-"
      },
      "source": [
        "## Given any topic and get the top 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7-W5LK5R7SU"
      },
      "source": [
        "Here we show 2 examples, one for searching for Alzheimer's disease, one for searching for losing weight. The search here can be any terms, although it will make more sense if it is something related to public health and social inequality. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4Vm-0k6qFU"
      },
      "source": [
        "def get_request_array(request, MAX_TOKEN):\n",
        "  request_token = tokenizer.encode_plus(request, max_length=MAX_TOKEN, # length from 128 to 20\n",
        "                                      truncation=True, padding='max_length',\n",
        "                                      return_tensors='pt')\n",
        "\n",
        "  request_id = request_token['input_ids'][0]\n",
        "  request_attention_mask = request_token['attention_mask'][0]\n",
        "\n",
        "  request_outputs = model(**request_token)\n",
        "  request_embeddings = request_outputs.last_hidden_state\n",
        "  request_mask = request_attention_mask.unsqueeze(-1).expand(request_embeddings.size()).float()\n",
        "  request_masked_embeddings = request_embeddings * request_mask\n",
        "  request_summed = torch.sum(request_masked_embeddings, 1)\n",
        "  request_summed_mask = torch.clamp(request_mask.sum(1), min=1e-9)\n",
        "  request_mean_pooled = request_summed / request_summed_mask\n",
        "  return request_mean_pooled.detach().numpy()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bTmy9wBHbUN"
      },
      "source": [
        "search_1 = \"Alzheimer\"\n",
        "search_2 = \"lesbian\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vXSgmz-CKlz"
      },
      "source": [
        "topic_array_1 = get_request_array(request=search_1, MAX_TOKEN=20)\n",
        "topic_array_2 = get_request_array(request=search_2, MAX_TOKEN=20)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URu4XPtufq1X"
      },
      "source": [
        "## cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZcRYFYlYxVw"
      },
      "source": [
        "Rank related topics by calculating the cosine similarity between the given topics and the categories in the candidate list.  \n",
        "\n",
        "Here we show the top 20 similar topics (the smaller the cosine it is, the less similar to the given topic the category it is)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8w8b8ruHuSw"
      },
      "source": [
        "def cosine_simi_list_for_one(topic_array):\n",
        "  simi_array = cosine_similarity(topic_array, Embeddings)\n",
        "  simi_list = simi_array.tolist()[0]\n",
        "  sorted_index = sorted(range(len(simi_list)), key=lambda k: simi_list[k])\n",
        "  sorted_index.reverse() # the smaller the cosine it is, the bigger angle between two, then the less similar between the two. So reverse here.\n",
        "  subs = list(map(dic.get, sorted_index, sorted_index))[:21] # only get the top 20 most similar words\n",
        "  return subs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ntYIDa51JDY",
        "outputId": "9cf9fc1b-8143-44ad-9dd8-5a55877a0eb0"
      },
      "source": [
        "cosine20_for_search_1 = cosine_simi_list_for_one(topic_array_1)\n",
        "print('the top 20 (cosine) related terms for ', search_1, 'is')\n",
        "print(cosine20_for_search_1)\n",
        "print('')\n",
        "cosine20_for_search_2 = cosine_simi_list_for_one(topic_array_2)\n",
        "print('the top 20 (cosine) related terms for ', search_2, 'is')\n",
        "print(cosine20_for_search_2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the top 20 (cosine) related terms for  Alzheimer is\n",
            "[\"alzheimer's disease\", 'parkinsons', 'schizophrenia', 'marburg virus', 'dementia with lewy bodies', 'ataxia', 'bipolar disorder', 'poverty in algeria', 'psychosis', 'infertility', 'otitis media', 'autistic spectrum disorder', 'vip syndrome', 'dementia', 'ebola vaccine', 'west nile virus', 'middle ear infection', 'stereotype threat', 'scurvy', 'psoriasis', 'poverty in nigeria']\n",
            "\n",
            "the top 20 (cosine) related terms for  lesbian is\n",
            "['transgender', 'recreation', 'genocide', 'farming', 'oppression', 'seasons', 'wealth', 'humanities', 'poverty', 'psychology', 'capitalist', 'anthropologist', 'exile', 'socialism', 'tourism', 'sport', 'piles', 'meditation', 'flood', 'researching', 'doi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npa93SaBf8NM"
      },
      "source": [
        "## euclidean_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC4GDo2GKdan"
      },
      "source": [
        "Rank related topics by calculating the euclidean distances between the given topics and the categories in the candidate list. \n",
        "\n",
        "Here we show the top 20 similar topics (the smaller the distance it is, the more similar to the given topic the category it is)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPcKaR2lzgQ"
      },
      "source": [
        "# the closer the distance is more small \n",
        "def eucli_distance_list_for_one(topic_array):\n",
        "  distance_array = euclidean_distances(topic_array, Embeddings)\n",
        "  distance_list = distance_array.tolist()[0]\n",
        "  sorted_index = sorted(range(len(distance_list)), key=lambda k: distance_list[k])\n",
        "  subs = list(map(dic.get, sorted_index, sorted_index))[:21]\n",
        "  return subs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBBJ366Hh6eb",
        "outputId": "6d95d20d-a3b7-4a0a-b435-425a79408735"
      },
      "source": [
        "eud20terms_for_search_1 = eucli_distance_list_for_one(topic_array_1)\n",
        "print('the top 20 (distance) related terms for ', search_1, 'is')\n",
        "print(eud20terms_for_search_1)\n",
        "print('')\n",
        "\n",
        "eud20terms_for_search_2 = eucli_distance_list_for_one(topic_array_2)\n",
        "print('the top 20 (distance) related terms for ', search_2, 'is')\n",
        "print(eud20terms_for_search_2)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the top 20 (distance) related terms for  Alzheimer is\n",
            "[\"alzheimer's disease\", 'parkinsons', 'schizophrenia', 'marburg virus', 'dementia with lewy bodies', 'ataxia', 'poverty in algeria', 'bipolar disorder', 'infertility', 'vip syndrome', 'ebola vaccine', 'psychosis', 'autistic spectrum disorder', 'dementia', 'otitis media', 'middle ear infection', 'stereotype threat', 'psoriasis', 'west nile virus', 'egalitarianism', 'poverty in nigeria']\n",
            "\n",
            "the top 20 (distance) related terms for  lesbian is\n",
            "['transgender', 'recreation', 'genocide', 'farming', 'oppression', 'seasons', 'wealth', 'humanities', 'poverty', 'psychology', 'capitalist', 'anthropologist', 'exile', 'socialism', 'tourism', 'sport', 'piles', 'meditation', 'flood', 'researching', 'doi']\n"
          ]
        }
      ]
    }
  ]
}