{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Label_arbitrary_paper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsZQGhAxld5D"
      },
      "source": [
        "## Load library and candidate list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGSDhZj7P7mE",
        "outputId": "a8909b33-fc30-448d-b9b3-3e2ba1cb90da"
      },
      "source": [
        "pip install pymediawiki"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymediawiki\n",
            "  Downloading pymediawiki-0.7.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pymediawiki) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pymediawiki) (4.6.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (1.24.3)\n",
            "Installing collected packages: pymediawiki\n",
            "Successfully installed pymediawiki-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0dPKAkHf1HG"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43PsHoF7Du9k"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/casszhao/FAIR/main/0901_full_list.csv'\n",
        "sorted_cat = pd.read_csv(url, header=None)\n",
        "sorted_cat = sorted_cat[0].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i4x-2tSG02o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e517cd4e-0aff-424a-b5ef-e142c1d7484c"
      },
      "source": [
        "sorted_cat_lowervob_list = list((map(lambda x: x.lower(), sorted_cat)))\n",
        "print(len(sorted_cat_lowervob_list))\n",
        "sorted_cat_list = list(set(sorted_cat_lowervob_list))\n",
        "print(len(sorted_cat_lowervob_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2159\n",
            "2159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgO-6o0dzXzA"
      },
      "source": [
        "**Example Abstract**\n",
        "\n",
        "Example to show how an abstract is processed\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccndMMdS40VL"
      },
      "source": [
        "abstract = 'how health care reform can transform the health of criminal justice involved individualsProvisions of the Affordable Care Act offer new opportunities to apply a public health and medical perspective to the complex relationship between involvement in the criminal justice system and the existence of fundamental health disparities. Incarceration can cause harm to individual and community health, but prisons and jails also hold enormous potential to play an active and beneficial role in the health care system and, ultimately, to improving health. Traditionally, incarcerated populations have been incorrectly viewed as isolated and self-contained communities with only peripheral importance to the public health at large. This misconception has resulted in missed opportunities to positively affect the health of both the individuals and the imprisoned community as a whole and potentially to mitigate risk behaviors that may contribute to incarceration. Both community and correctional health care professionals can capitalize on these opportunities by working together to advocate for the health of the criminal justice-involved population and their communities. We present a set of recommendations for the improvement of both correctional health care, such as improving systems of external oversight and quality management, and access to community-based care, including establishing strategies for postrelease care and medical record transfers. ' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advihn3-5P_x"
      },
      "source": [
        "## Step 1: Data pre-processing (extract nouns from text).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdlV4Jdj5Z_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea0a433-b05f-4e2c-fb02-046df4dc9102"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "stopwords_list = stopwords.words('english')\n",
        "print(len(stopwords_list))\n",
        "extended = ['methodology', 'study', 'use', 'purpose', 'research', 'conclusion',\n",
        "            'research', 'paper', 'background', 'dissertation', 'essays',\n",
        "            'purpose', 'addition', 'elsevier']\n",
        "stopwords_list=stopwords_list+extended\n",
        "\n",
        "print(len(stopwords_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "179\n",
            "193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VrONAeCgTIS"
      },
      "source": [
        "words = [word for word in word_tokenize(abstract) if word.lower() not in stopwords_list]\n",
        "nostop_abstract = \" \".join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAeyAHjbUgE3"
      },
      "source": [
        "## Step 2: Identify terms in the abstract which are also in the list of candidate categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liMuMSg1VJji"
      },
      "source": [
        "def generate_ngrams(s, n):\n",
        "    # Convert to lowercases\n",
        "    s = s.lower()\n",
        "    \n",
        "    # Replace all none alphanumeric characters with spaces\n",
        "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
        "    \n",
        "    # Break sentence in the token, remove empty tokens\n",
        "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
        "    \n",
        "    # Use the zip function to help us generate n-grams\n",
        "    # Concatentate the tokens into ngrams and return\n",
        "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
        "    return [\" \".join(ngram) for ngram in ngrams]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKePoGUdVNHG"
      },
      "source": [
        "def get_matched_gram(abstract):  \n",
        "  uni_gram = nltk.word_tokenize(abstract)\n",
        "  bi_gram = generate_ngrams(abstract, 2)\n",
        "  tri_gram = generate_ngrams(abstract, 3)\n",
        "\n",
        "  all = uni_gram + bi_gram + tri_gram\n",
        "\n",
        "  all_lower = list((map(lambda x: x.lower(), all)))\n",
        "\n",
        "  matched = []\n",
        "  for gram in all_lower:\n",
        "    if gram in sorted_cat_lowervob_list:\n",
        "      matched.append(gram)\n",
        "    else:\n",
        "      pass\n",
        "  return list(set(matched))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eCtzDZMavOK"
      },
      "source": [
        "matched_list = get_matched_gram(abstract)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLV13Gr-5JdP",
        "outputId": "6432cc52-92da-45a0-aaa5-0da73e41354f"
      },
      "source": [
        "matched_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['health disparities',\n",
              " 'health care',\n",
              " 'community',\n",
              " 'health care reform',\n",
              " 'health',\n",
              " 'health care system',\n",
              " 'public health',\n",
              " 'individual',\n",
              " 'community health']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn-cmSYc5TYH"
      },
      "source": [
        "## Step 3: Check Wikipedia categories associated with each noun and return those that appear in the candidate list. \n",
        "\n",
        "1.   Identify nouns in abstract\n",
        "2.   Retrive Wikipedia categories associated with each noun\n",
        "3.   Save list of categories which also appear in the candidate list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3NeQF8Fkq31"
      },
      "source": [
        "is_noun = lambda pos: pos[:2] == 'NN'\n",
        "#   # do the nlp stuff\n",
        "tokenized = nltk.word_tokenize(nostop_abstract)\n",
        "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
        "nouns = list(set(nouns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ngFuf_R5ZJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41106dc0-05db-4583-85ce-fd26831de7bc"
      },
      "source": [
        "pip install pymediawiki"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymediawiki in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pymediawiki) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pymediawiki) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG1T3Ct95a1P"
      },
      "source": [
        "from mediawiki import MediaWiki\n",
        "wikipedia = MediaWiki()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG5JMAEs5btd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b1ebaf-e4a9-4353-f32d-ab0f5732e385"
      },
      "source": [
        "search_list = list(set(nouns + matched_list))\n",
        "one_text_cats_list = []\n",
        "for topic in search_list:\n",
        "  try:\n",
        "    p = wikipedia.page(topic)\n",
        "    one_nouns_cat = p.categories\n",
        "    one_text_cats_list = one_text_cats_list + one_nouns_cat\n",
        "  except:\n",
        "    print('no wikipedia search result for ', topic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no wikipedia search result for  quality\n",
            "no wikipedia search result for  Act\n",
            "no wikipedia search result for  access\n",
            "no wikipedia search result for  relationship\n",
            "no wikipedia search result for  care\n",
            "no wikipedia search result for  misconception\n",
            "no wikipedia search result for  Care\n",
            "no wikipedia search result for  disparities\n",
            "no wikipedia search result for  transfers\n",
            "no wikipedia search result for  play\n",
            "no wikipedia search result for  record\n",
            "no wikipedia search result for  opportunities\n",
            "no wikipedia search result for  perspective\n",
            "no wikipedia search result for  set\n",
            "no wikipedia search result for  transform\n",
            "no wikipedia search result for  complex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0zCY9CxNLgt"
      },
      "source": [
        "**Match the pre-defined categories**\n",
        "\n",
        "\n",
        "pre-defined vocabulary: sorted_cat_lowervob_list\n",
        "from the vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpLyjRLduwuX"
      },
      "source": [
        "maching categories if it contains pre-defined vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAFHwh8MtTga",
        "outputId": "4096ca6c-44eb-4e26-c131-ebe6dea7027e"
      },
      "source": [
        "saved_cat_list = []\n",
        "for one_cat in one_text_cats_list:\n",
        "  if one_cat.lower() in sorted_cat_lowervob_list:\n",
        "    saved_cat_list.append(one_cat.lower())\n",
        "  else:\n",
        "    pass\n",
        "saved_cat_list = list(set(saved_cat_list))\n",
        "print(saved_cat_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['health economics', 'medical humanities', 'sanitation', 'health care', 'health equity', 'euthenics', 'social problems in medicine', 'primary care', 'determinants of health', 'medical sociology', 'health policy', 'demography', 'economic inequality', 'organizational theory', 'community', 'health', 'public health', 'health care reform']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0t8SzyRum5S"
      },
      "source": [
        "## Step 4: Produce combined list of categories identified in previous steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcx5PgW9lcii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0d1739-b91d-4890-e3e5-cfe412f81954"
      },
      "source": [
        "combined_identical_matched = matched_list + saved_cat_list\n",
        "combined_identical_matched"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['health disparities',\n",
              " 'health care',\n",
              " 'community',\n",
              " 'health care reform',\n",
              " 'health',\n",
              " 'health care system',\n",
              " 'public health',\n",
              " 'individual',\n",
              " 'community health',\n",
              " 'health economics',\n",
              " 'medical humanities',\n",
              " 'sanitation',\n",
              " 'health care',\n",
              " 'health equity',\n",
              " 'euthenics',\n",
              " 'social problems in medicine',\n",
              " 'primary care',\n",
              " 'determinants of health',\n",
              " 'medical sociology',\n",
              " 'health policy',\n",
              " 'demography',\n",
              " 'economic inequality',\n",
              " 'organizational theory',\n",
              " 'community',\n",
              " 'health',\n",
              " 'public health',\n",
              " 'health care reform']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}
